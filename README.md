# Food_Detection-


ğŸ“˜ README (English):

ğŸ½ï¸ Food Classification Project

This project provides a desktop application for classifying food images using a deep learning model (ResNet50).
It integrates a PyQt6 graphical interface with a FastAPI backend, which serves the trained model for predictions.

ğŸš€ Features

Upload an image of a meal from your computer.

Detect the type of food using a trained efficientnet_b0 model.

âœ… Display:

Meal name

Confidence percentage

Estimated calories

Clean and modern UI with buttons (Choose Photo, Detect).

Separate result window showing the uploaded image and classification results.

ğŸ“ŠDataset:
The dataset used in this project is the Food-101 tiny, which contains 200 images for each  food category.
For this project, we selected 10 representative food classes to train and evaluate the model.
Source: Food-101 tiny Dataset on Kaggle


âœ… Model Overview : 

Food Classifier using EfficientNet
This project implements a food image classifier using EfficientNet with several modern deep learning techniques to improve performance:

Backbone: EfficientNet-B0 (with optional use of timm for more flexible architectures).
Data Augmentation: Random resized crop, horizontal flip, rotation, and color jitter to increase robustness.
Optimizer: AdamW with weight decay for stable training.
Label Smoothing: Reduces overconfidence in predictions.
Mixed-Precision Training: Uses torch.cuda.amp to accelerate training on GPUs while saving memory.
Learning Rate Scheduler: Cosine annealing or ReduceLROnPlateau.
Balanced Sampling: Optionally uses weighted sampler to handle class imbalance.
Early Stopping: Stops training when validation accuracy does not improve for several epochs.
Evaluation Metrics: Accuracy and loss for both training and validation.
Deployment: FastAPI-based REST API for predicting food class, confidence, and estimated calories from images.
Number of classes: 10 (apple_pie, bibimbap, cannoli, chicken_curry, falafel, french_toast, ice_cream, ramen, sushi, tiramisu)

This model can be easily extended to more classes or different EfficientNet variants (B1-B7) if needed.

ğŸ› ï¸ Tech Stack :

Frontend (GUI): PyQt6
Backend (API): FastAPI + Uvicorn
Model: PyTorch (efficientnet_b0 fine-tuned on 10 food classes)
Image Processing: Torchvision, PIL

ğŸ“‚ Project Structure:


```bash
ğŸ“‚ Food_Project
â”œâ”€â”€ api.py               # FastAPI backend (model + API endpoint)
â”œâ”€â”€ main.py              # PyQt6 GUI (frontend)
â”œâ”€â”€ chart/
â”‚   â””â”€â”€ pic.png
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model_efficientnet_b0.pth
â”‚   â”œâ”€â”€ final_efficientnet_b0.pth  # Trained model
â”‚   â””â”€â”€ train_log.csv
â””â”€â”€ interfaces/
    â””â”€â”€ food.png          # Background image for GUI

```

âš™ï¸ Setup & Installation

Clone the repository:
git clone <repo-link>
cd Food_Project
Install dependencies:
pip install -r requirements.txt


ğŸ”¹ Main requirements:
PyQt6
FastAPI
Uvicorn
Torch, Torchvision
Pillow
Requests

ğŸš€ Run the API (backend):
python api.py
You should see:
Uvicorn running on http://127.0.0.1:8000
Run the GUI (frontend):
python main.py


ğŸ“Š Classes & Calories:
The model supports 10 food classes (each class with 150 pictures) : 
apple_pie (300 kcal)
bibimbap (450 kcal)
cannoli (350 kcal)
chicken_curry (500 kcal)
falafel (350 kcal)
french_toast (400 kcal)
ice_cream (200 kcal)
ramen (550 kcal)
sushi (300 kcal)
tiramisu (450 kcal)


ğŸ–¼ï¸ Usage Flow:
Launch the app (main.py).
Select an image via Choose Photo.
Click Detect â†’ the GUI sends the image to the API.
The API runs the model and returns: food class, confidence %, and calories.
"A Result Window pops up displaying the image and results."



ğŸš€ Future Improvements : 
Expand Dataset:
     Add more food categories to cover a wider range of cuisines.
Nutritional Info:  
     Extend predictions to include protein, fat, carbs, etc., not just calories.
Mobile App Version: 
    Build an Android/iOS app for easier use.
Cloud Deployment: 
    Host the API on cloud services (Heroku, AWS, or Azure) so it works anywhere without running locally.
Offline Mode:
    Package the model inside the GUI to work without internet/API dependency.
User History:
    Save classification history for each user (with date/time).
Improved Accuracy: 
    Try other models (EfficientNet, Vision Transformers) or ensemble methods.
Multi-language Support:
     Add more languages to the GUI for wider usability.



_____________________________________________________________________--

ğŸ“˜ README (Ø¹Ø±Ø¨ÙŠ):
ğŸ½ï¸ Ù…Ø´Ø±ÙˆØ¹ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø·Ø¹Ù…Ø©:

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠÙ‚Ø¯Ù… ØªØ·Ø¨ÙŠÙ‚ Ø³Ø·Ø­ Ù…ÙƒØªØ¨ Ù„ØªØµÙ†ÙŠÙ ØµÙˆØ± Ø§Ù„Ø£Ø·Ø¹Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø¹Ù…ÙŠÙ‚ (ResNet50).
Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠØ¯Ù…Ø¬ Ø¨ÙŠÙ† ÙˆØ§Ø¬Ù‡Ø© Ø±Ø³ÙˆÙ…ÙŠØ© (PyQt6) Ùˆ Ø®Ø§Ø¯Ù… Ø®Ù„ÙÙŠ (FastAPI) ÙŠØ¹Ù…Ù„ ÙƒÙˆØ³ÙŠØ· Ø¨ÙŠÙ† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„.


ğŸš€ Ø§Ù„Ù…Ø²Ø§ÙŠØ§:

Ø±ÙØ¹ ØµÙˆØ±Ø© ÙˆØ¬Ø¨Ø© Ù…Ù† Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….
Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø·Ø¹Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ efficientnet_b0 Ù…Ø¯Ø±Ù‘Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§.

âœ… Ø¹Ø±Ø¶:

Ø§Ø³Ù… Ø§Ù„ÙˆØ¬Ø¨Ø©
Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©
Ø§Ù„Ø³Ø¹Ø±Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±ÙŠØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
ÙˆØ§Ø¬Ù‡Ø© Ø±Ø³ÙˆÙ…ÙŠØ© Ø­Ø¯ÙŠØ«Ø© Ù…Ø¹ Ø£Ø²Ø±Ø§Ø± (Choose Photo, Detect).
Ù†Ø§ÙØ°Ø© Ù…Ù†ÙØµÙ„Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.


ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª   Food-101 tiny ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 200 ØµÙˆØ±Ø© Ù„ÙƒÙ„ ØµÙ†Ù Ù…Ù† Ø§Ù„Ù€ 10 Ø£ØµÙ†Ø§Ù Ù…Ù† Ø§Ù„Ø£Ø·Ø¹Ù…Ø© 
ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ù‚Ù…Ù†Ø§ Ø¨Ø§Ø®ØªÙŠØ§Ø± 10 Ø£ØµÙ†Ø§Ù ÙÙ‚Ø· Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªÙ‚ÙŠÙŠÙ…Ù‡.
Ø§Ù„Ù…ØµØ¯Ø±: Food-101 tiny Ø¹Ù„Ù‰ Kaggle


ğŸ› ï¸ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„:
Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (GUI): PyQt6
Ø§Ù„Ø®Ù„ÙÙŠØ© (API): FastAPI + Uvicorn
Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: PyTorch (ResNet50 Ù…Ø¯Ø±Ù‘Ø¨ Ø¹Ù„Ù‰ 10 Ø£ØµÙ†Ø§Ù Ø·Ø¹Ø§Ù…) ÙƒÙ„ ØµÙ†Ù 200 ØµÙˆØ±Ù‡.


ğŸ“‚ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:
Food_Project/
â”‚
â”œâ”€â”€ api.py                 # ÙƒÙˆØ¯ Ø§Ù„Ø®Ø§Ø¯Ù… (Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ + API)
â”œâ”€â”€ main.py  
# ÙƒÙˆØ¯ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø³ÙˆÙ…ÙŠØ©
â”œâ”€â”€chart/
     â””â”€â”€pic.png
â”œâ”€â”€ models/
     â””â”€â”€ best_model_efficientnet_b0.pth
     â””â”€â”€ final_efficientnet_b0.pth       # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ù‘Ø¨
â”‚    â””â”€â”€ train_log.csv     
â”œâ”€â”€ interfaces/
â”‚   â””â”€â”€ food.png           # ØµÙˆØ±Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©

âš™ï¸ Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ´ØºÙŠÙ„

ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:
git clone <repo-link>
cd Food_Project
ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:
pip install -r requirements.txt




ğŸ”¹Ø£Ù‡Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª:

PyQt6

FastAPI

Uvicorn

Torch, Torchvision

Pillow

Requests


ğŸš€ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… (API):

python api.py

Ø³ÙŠØ¸Ù‡Ø±:
Uvicorn running on http://127.0.0.1:8000

python main.py


ğŸ“Š Ø§Ù„Ø£ØµÙ†Ø§Ù ÙˆØ§Ù„Ø³Ø¹Ø±Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±ÙŠØ©:

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯Ø¹Ù… 10 Ø£ØµÙ†Ø§Ù Ø·Ø¹Ø§Ù…:
ÙØ·ÙŠØ±Ø© Ø§Ù„ØªÙØ§Ø­ (300 Ø³Ø¹Ø±Ø©)
Ø¨ÙŠØ¨ÙŠÙ…Ø¨Ø§Ø¨ (450 Ø³Ø¹Ø±Ø©)
ÙƒØ§Ù†ÙˆÙ„ÙŠ (350 Ø³Ø¹Ø±Ø©)
ÙƒØ§Ø±ÙŠ Ø§Ù„Ø¯Ø¬Ø§Ø¬ (500 Ø³Ø¹Ø±Ø©)
ÙÙ„Ø§ÙÙ„ (350 Ø³Ø¹Ø±Ø©)
ÙØ±Ù†Ø´ ØªÙˆØ³Øª (400 Ø³Ø¹Ø±Ø©)
Ø¢ÙŠØ³ ÙƒØ±ÙŠÙ… (200 Ø³Ø¹Ø±Ø©)
Ø±Ø§Ù…Ù† (550 Ø³Ø¹Ø±Ø©)
Ø³ÙˆØ´ÙŠ (300 Ø³Ø¹Ø±Ø©)
ØªÙŠØ±Ø§Ù…ÙŠØ³Ùˆ (450 Ø³Ø¹Ø±Ø©)

ğŸ–¼ï¸ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:

ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (main.py).

Ø§Ø®ØªÙŠØ§Ø± ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø²Ø± Choose Photo.

Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Detect â†’ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ØªØ±Ø³Ù„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù€ API.

Ø§Ù„Ø®Ø§Ø¯Ù… ÙŠØ¹ÙŠØ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù†ÙˆØ¹ Ø§Ù„Ø·Ø¹Ø§Ù… + Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© + Ø§Ù„Ø³Ø¹Ø±Ø§Øª.

Ù†Ø§ÙØ°Ø© Ø¬Ø¯ÙŠØ¯Ø© ØªØ¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬.



ğŸš€ Ø§Ù„ØªØ·ÙˆÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© :


ØªÙˆØ³ÙŠØ¹ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
      Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø£ØµÙ†Ø§Ù Ø§Ù„Ø£Ø·Ø¹Ù…Ø© Ù„ØªØºØ·ÙŠØ© Ù…Ø·Ø§Ø¨Ø® Ù…Ø®ØªÙ„ÙØ©.

Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºØ°Ø§Ø¦ÙŠØ© Ø´Ø§Ù…Ù„Ø©:  
      Ø¹Ø±Ø¶ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© (Ø§Ù„Ø¨Ø±ÙˆØªÙŠÙ†ØŒ Ø§Ù„Ø¯Ù‡ÙˆÙ†ØŒ Ø§Ù„ÙƒØ±Ø¨ÙˆÙ‡ÙŠØ¯Ø±Ø§Øª) Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³Ø¹Ø±Ø§Øª.

Ø¥ØµØ¯Ø§Ø± Ù„Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø°ÙƒÙŠØ©: 
      Ø¨Ù†Ø§Ø¡ Ù†Ø³Ø®Ø© Ù…Ø®ØµØµØ© Ù„Ù„Ø£Ù†Ø¯Ø±ÙˆÙŠØ¯ Ùˆ iOS.

Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©: 
      Ø±ÙØ¹ Ø§Ù„Ù€ API Ø¹Ù„Ù‰ Ø®ÙˆØ§Ø¯Ù… Ø³Ø­Ø§Ø¨ÙŠØ© (Heroku, AWS, Azure) Ù„ÙŠØ¹Ù…Ù„ Ù…Ù† Ø£ÙŠ Ù…ÙƒØ§Ù† Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ.

ÙˆØ¶Ø¹ Ø¹Ø¯Ù… Ø§Ù„Ø§ØªØµØ§Ù„: 
      Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ù„ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª Ø£Ùˆ API Ø®Ø§Ø±Ø¬ÙŠ.

Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„:
      ØªØ®Ø²ÙŠÙ† ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø¹ Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®.

ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø©: 
     ØªØ¬Ø±Ø¨Ø© Ù†Ù…Ø§Ø°Ø¬ Ø£Ø®Ø±Ù‰ (EfficientNet, Vision Transformers) Ø£Ùˆ Ø§Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† Ø£ÙƒØ«Ø± Ù…Ù† Ù†Ù…ÙˆØ°Ø¬.

Ø¯Ø¹Ù… Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©:
     Ø¥Ø¶Ø§ÙØ© Ù„ØºØ§Øª Ù…Ø®ØªÙ„ÙØ© Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù….


# Model Accuracy:

91.33 


# Chart about the differences between Training Accuracy vs Test Accuracy:

![Accuracy Chart](chart/pic.png)

# Results:
No Overfitting .
A great Accuracy .
































